{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/a-forty-two/EY-batch5-10thJune24/blob/main/01_Ey_Batch4_IntroToNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8OzfeWG8vzm"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Unstructured data -> derive insights or make decisions or give instructions or take automated actions\n",
    "\n",
    "# data lake -> store the data\n",
    "# read and Feature engineer-> data pre-processing\n",
    "# train the model -> cluster/distributed processing\n",
    "# test the model -> monitoring infra\n",
    "# evaluate the model-> same monitoring infra\n",
    "# deploy the model -> containers, Kubernetes, Flask API....\n",
    "\n",
    "\n",
    " # data pre-processing\n",
    " #\n",
    " # text data -> Document -> pages -> paragraphs -> sentences -> words\n",
    " # SEGMENTATION\n",
    "\n",
    " # individual components to analyze?\n",
    " # TOKENIZATION\n",
    "\n",
    " # The cat is hungry. -> [The, cat, is, hungry] or [The, cat, is, hungry, .]\n",
    "\n",
    " # multiple words-> The Himalayas are tall -> ['The Himalayas', 'are', 'tall']\n",
    "\n",
    " # stopwords -> a, an, the -> inconsequential words!\n",
    " # sentiment analysis -> a, an, the could be used in both pos and neg sentiments!\n",
    "\n",
    " # order to figure out these complex grammars:\n",
    " # PART of SPEECH tagging -> nouns, pronouns, verbs, adverbs, adjectives\n",
    "\n",
    " # 'The himalayas', 'Peter Parker', 'The Batman', -> NAMED entity recognition-> from POS\n",
    " # The cat eats the mouse\n",
    " # <noun> - <verb> - <noun> -> from POS tagging, you could also figure out relationship in sentences\n",
    "\n",
    " # Dependency parsing and tree-> which token is dependent on another token!\n",
    " # The cat is hungry for cheese, a cat is hungry for rat\n",
    "\n",
    " # verb-> hungry\n",
    " # nouns-> cat, cheese\n",
    " # root word-> hungry\n",
    "\n",
    " #              hungry\n",
    " #              /     \\\n",
    " #          cat         for\n",
    " #          /   \\     |     \\\n",
    " #        PH    is     rat  cheese\n",
    " #      /   \\\n",
    " #      a    the\n",
    "\n",
    "\n",
    " # Feature for the model training -> we then pass them to neural networks for weights and bias calculation\n",
    " # the resulting features when very very deep and very very large -> LLM\n",
    "\n",
    "\n",
    " # VECTORS -> also knowns as dimensions, tensors\n",
    "\n",
    " # Embedding on these vectors -> embedding is what a neural network learns and forms patterns!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from nltk) (2024.4.28)\n",
      "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from nltk) (4.66.2)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n",
      "Requirement already satisfied: spacy in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (3.4.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: jinja2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (2.11.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (8.1.12)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (1.10.15)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (0.11.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (4.66.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: setuptools in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: language-data>=1.2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (0.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Installing collected packages: typer\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.12.3\n",
      "    Uninstalling typer-0.12.3:\n",
      "      Successfully uninstalled typer-0.12.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastapi-cli 0.0.4 requires typer>=0.12.3, but you have typer 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed typer-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PJYB5DQKAGCm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk # very good library, but has a few challenges, more stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_IAwSLR9AmCV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 11:02:19.234237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-09-04 11:02:19.234282: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-09-04 11:02:20.753309: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2024-09-04 11:02:26.846157: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-09-04 11:02:26.846206: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (shanuapril1): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import spacy # frequently updates, sometimes goes bonkers, a Lot more methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDrQWPaeAqDM",
    "outputId": "8c01d15b-b32d-409b-de7b-3959a48b42dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/azureuser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/azureuser/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libs-> load a dictionary model -> start tokenizing\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjKOe821BIBU",
    "outputId": "7e30f6f1-6f39-43c2-ff82-a7dae7dbcf33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Doctor', 'who', 'can', 'travel', 'through', 'time', 'and', 'space', '!']\n"
     ]
    }
   ],
   "source": [
    "# NLTK\n",
    "sentence = 'Doctor who can travel through time and space!'\n",
    "tokens_nltk = word_tokenize(sentence)\n",
    "print(tokens_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "12tF1lvsBRv_"
   },
   "outputs": [],
   "source": [
    "#spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDKm0KB4Bbwi",
    "outputId": "205933cd-2782-4150-e6f5-b5403128b080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doctor who can travel through time and space ! "
     ]
    }
   ],
   "source": [
    "sentence = 'Doctor who can travel through time and space!'\n",
    "tokens_spacy = nlp(sentence)\n",
    "for token in tokens_spacy:\n",
    "  print(token.text, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wuhtv4h1BgNi",
    "outputId": "4c6b7e21-a469-4c0a-ba4e-78c0238dfc02"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46999b9b1bb94d4c8254d9e597b63fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b28a269c5745aaa01458bee3f17fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e77f9672bb417da2cfaff319bf0390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91065e43829b464da3fc504e63cbb868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['doctor', 'who', 'can', 'travel', 'through', 'time', 'and', 'space', '!']\n"
     ]
    }
   ],
   "source": [
    "# hugging face\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokens_hf = tokenizer.tokenize(sentence)\n",
    "print(tokens_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kkU6DZEoBxTt",
    "outputId": "9f0e5781-1010-44aa-f4a4-65c3821e28de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n"
     ]
    }
   ],
   "source": [
    "token = tokens_nltk[0]\n",
    "print(dir(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Sd2_7vcC08I",
    "outputId": "44ec81e9-c99a-467b-da95-da3ce33cdf9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', 'ancestors', 'check_flag', 'children', 'cluster', 'conjuncts', 'dep', 'dep_', 'doc', 'ent_id', 'ent_id_', 'ent_iob', 'ent_iob_', 'ent_kb_id', 'ent_kb_id_', 'ent_type', 'ent_type_', 'get_extension', 'has_dep', 'has_extension', 'has_head', 'has_morph', 'has_vector', 'head', 'i', 'idx', 'iob_strings', 'is_alpha', 'is_ancestor', 'is_ascii', 'is_bracket', 'is_currency', 'is_digit', 'is_left_punct', 'is_lower', 'is_oov', 'is_punct', 'is_quote', 'is_right_punct', 'is_sent_end', 'is_sent_start', 'is_space', 'is_stop', 'is_title', 'is_upper', 'lang', 'lang_', 'left_edge', 'lefts', 'lemma', 'lemma_', 'lex', 'lex_id', 'like_email', 'like_num', 'like_url', 'lower', 'lower_', 'morph', 'n_lefts', 'n_rights', 'nbor', 'norm', 'norm_', 'orth', 'orth_', 'pos', 'pos_', 'prefix', 'prefix_', 'prob', 'rank', 'remove_extension', 'right_edge', 'rights', 'sent', 'sent_start', 'sentiment', 'set_extension', 'set_morph', 'shape', 'shape_', 'similarity', 'subtree', 'suffix', 'suffix_', 'tag', 'tag_', 'tensor', 'text', 'text_with_ws', 'vector', 'vector_norm', 'vocab', 'whitespace_']\n"
     ]
    }
   ],
   "source": [
    "token = tokens_spacy[0]\n",
    "print(dir(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRFXMzNoC3MQ",
    "outputId": "0d52b69f-04c9-44e5-ad57-75243de208af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities along with their type\n",
      "Shaktiman PERSON\n",
      "New Delhi GPE\n",
      "\n",
      "\n",
      "\n",
      "Token grammatical properties\n",
      "Shaktiman Shaktiman PROPN NNP nsubj\n",
      "********\n",
      "likes like VERB VBZ ROOT\n",
      "********\n",
      "travelling travel VERB VBG xcomp\n",
      "********\n",
      "through through ADP IN prep\n",
      "********\n",
      "time time NOUN NN pobj\n",
      "********\n",
      "and and CCONJ CC cc\n",
      "********\n",
      "space space NOUN NN conj\n",
      "********\n",
      "on on ADP IN prep\n",
      "********\n",
      "his his PRON PRP$ poss\n",
      "********\n",
      "penguin penguin NOUN NN pobj\n",
      "********\n",
      ". . PUNCT . punct\n",
      "********\n",
      "He he PRON PRP nsubj\n",
      "********\n",
      "lives live VERB VBZ ROOT\n",
      "********\n",
      "in in ADP IN prep\n",
      "********\n",
      "New New PROPN NNP compound\n",
      "********\n",
      "Delhi Delhi PROPN NNP pobj\n",
      "********\n",
      "! ! PUNCT . punct\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization and stemming-> 2 ways in which words are reduced to their base form\n",
    "sentence = 'Shaktiman likes travelling through time and space on his penguin. He lives in New Delhi!'\n",
    "tokens_spacy = nlp(sentence)\n",
    "\n",
    "print('Named Entities along with their type')\n",
    "for ents in tokens_spacy.ents:\n",
    "  print(ents.text, ents.label_)\n",
    "\n",
    "\n",
    "print( )\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Token grammatical properties')\n",
    "\n",
    "for token in tokens_spacy:\n",
    "  print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_)\n",
    "\n",
    "  print('********')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eGh2ogrtDfFj"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "pv14sZP7FOR8",
    "outputId": "8416efb1-cc4a-4a2b-bab2-ed8385497fb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"abc147d0616f4fc39f149e03835f44f7-0\" class=\"displacy\" width=\"2675\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Shaktiman</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">likes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">travelling</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">through</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">time</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">space</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">his</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">penguin.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">He</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">lives</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">New</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">Delhi!</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-abc147d0616f4fc39f149e03835f44f7-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-abc147d0616f4fc39f149e03835f44f7-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-abc147d0616f4fc39f149e03835f44f7-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-abc147d0616f4fc39f149e03835f44f7-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390.0,266.5 L398.0,254.5 382.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-abc147d0616f4fc39f149e03835f44f7-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-abc147d0616f4fc39f149e03835f44f7-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-abc147d0616f4fc39f149e03835f44f7-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-abc147d0616f4fc39f149e03835f44f7-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-abc147d0616f4fc39f149e03835f44f7-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-abc147d0616f4fc39f149e03835f44f7-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-abc147d0616f4fc39f149e03835f44f7-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-abc147d0616f4fc39f149e03835f44f7-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-abc147d0616f4fc39f149e03835f44f7-0-6\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-abc147d0616f4fc39f149e03835f44f7-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,266.5 L1283.0,254.5 1267.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-abc147d0616f4fc39f149e03835f44f7-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-abc147d0616f4fc39f149e03835f44f7-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-abc147d0616f4fc39f149e03835f44f7-0-8\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,89.5 1620.0,89.5 1620.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-abc147d0616f4fc39f149e03835f44f7-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1620.0,266.5 L1628.0,254.5 1612.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-abc147d0616f4fc39f149e03835f44f7-0-9\" stroke-width=\"2px\" d=\"M1820,264.5 C1820,177.0 1965.0,177.0 1965.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-abc147d0616f4fc39f149e03835f44f7-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,266.5 L1812,254.5 1828,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-abc147d0616f4fc39f149e03835f44f7-0-10\" stroke-width=\"2px\" d=\"M1995,264.5 C1995,177.0 2140.0,177.0 2140.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-abc147d0616f4fc39f149e03835f44f7-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2140.0,266.5 L2148.0,254.5 2132.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-abc147d0616f4fc39f149e03835f44f7-0-11\" stroke-width=\"2px\" d=\"M2345,264.5 C2345,177.0 2490.0,177.0 2490.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-abc147d0616f4fc39f149e03835f44f7-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2345,266.5 L2337,254.5 2353,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-abc147d0616f4fc39f149e03835f44f7-0-12\" stroke-width=\"2px\" d=\"M2170,264.5 C2170,89.5 2495.0,89.5 2495.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-abc147d0616f4fc39f149e03835f44f7-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2495.0,266.5 L2503.0,254.5 2487.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(tokens_spacy, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtCxiJfTFTM9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNNQJSKGNv5VC7Gx5c8SNWp",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
